{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2363281e-564d-46a2-8515-857e7dbe5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0fd214-a3c4-4111-9b9c-56862a301d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old_analysis = pd.read_csv(r\"..\\1_Data\\df_analysis.csv\")\n",
    "df_original = pd.read_csv(r\"..\\1_Data\\df_cleaned.csv\")\n",
    "df_analysis = df_original.copy()\n",
    "df_ML = df_analysis.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4edb2d15-e13a-48cb-9c44-1a6ce0e58061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37583 entries, 0 to 37582\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   fullAddress            37583 non-null  object \n",
      " 1   postcode               37583 non-null  object \n",
      " 2   country                37583 non-null  object \n",
      " 3   outcode                37583 non-null  object \n",
      " 4   latitude               37583 non-null  float64\n",
      " 5   longitude              37583 non-null  float64\n",
      " 6   bathrooms              37583 non-null  float64\n",
      " 7   bedrooms               37583 non-null  float64\n",
      " 8   floorAreaSqM           37583 non-null  float64\n",
      " 9   livingRooms            37583 non-null  float64\n",
      " 10  tenure                 37583 non-null  object \n",
      " 11  propertyType           37583 non-null  object \n",
      " 12  currentEnergyRating    37583 non-null  object \n",
      " 13  soldYear               37583 non-null  int64  \n",
      " 14  soldT                  37583 non-null  object \n",
      " 15  soldPrice              37583 non-null  int64  \n",
      " 16  sqmPrice               37583 non-null  float64\n",
      " 17  size_bucket            37583 non-null  object \n",
      " 18  construction_age_band  37583 non-null  object \n",
      " 19  in_conservation_area   37583 non-null  int64  \n",
      " 20  area_code              37583 non-null  object \n",
      " 21  sqm_approx             37583 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(11)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ML.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973345b4-a024-4de9-9608-5f8742fd1e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>floorAreaSqM</th>\n",
       "      <th>livingRooms</th>\n",
       "      <th>soldYear</th>\n",
       "      <th>soldPrice</th>\n",
       "      <th>sqmPrice</th>\n",
       "      <th>in_conservation_area</th>\n",
       "      <th>sqm_approx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>3.758300e+04</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "      <td>37583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.509197</td>\n",
       "      <td>-0.117340</td>\n",
       "      <td>1.485299</td>\n",
       "      <td>2.382833</td>\n",
       "      <td>100.520661</td>\n",
       "      <td>1.237368</td>\n",
       "      <td>2023.328473</td>\n",
       "      <td>8.119169e+05</td>\n",
       "      <td>7616.738752</td>\n",
       "      <td>0.289972</td>\n",
       "      <td>100.511668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056477</td>\n",
       "      <td>0.089292</td>\n",
       "      <td>0.733059</td>\n",
       "      <td>1.290800</td>\n",
       "      <td>60.835119</td>\n",
       "      <td>0.611463</td>\n",
       "      <td>0.469664</td>\n",
       "      <td>9.214488e+05</td>\n",
       "      <td>3867.971948</td>\n",
       "      <td>0.453755</td>\n",
       "      <td>60.871258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>51.386653</td>\n",
       "      <td>-0.347055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>66.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.465565</td>\n",
       "      <td>-0.184005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>3.750000e+05</td>\n",
       "      <td>5460.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51.501828</td>\n",
       "      <td>-0.120158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>5.300000e+05</td>\n",
       "      <td>6854.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.549781</td>\n",
       "      <td>-0.054122</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>9.050000e+05</td>\n",
       "      <td>8750.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>51.665454</td>\n",
       "      <td>0.138188</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>2.250000e+07</td>\n",
       "      <td>68613.330000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude     longitude     bathrooms      bedrooms  floorAreaSqM  \\\n",
       "count  37583.000000  37583.000000  37583.000000  37583.000000  37583.000000   \n",
       "mean      51.509197     -0.117340      1.485299      2.382833    100.520661   \n",
       "std        0.056477      0.089292      0.733059      1.290800     60.835119   \n",
       "min       51.386653     -0.347055      1.000000      1.000000     10.000000   \n",
       "25%       51.465565     -0.184005      1.000000      1.000000     59.000000   \n",
       "50%       51.501828     -0.120158      1.000000      2.000000     78.000000   \n",
       "75%       51.549781     -0.054122      2.000000      3.000000    129.000000   \n",
       "max       51.665454      0.138188      8.000000      9.000000    500.000000   \n",
       "\n",
       "        livingRooms      soldYear     soldPrice      sqmPrice  \\\n",
       "count  37583.000000  37583.000000  3.758300e+04  37583.000000   \n",
       "mean       1.237368   2023.328473  8.119169e+05   7616.738752   \n",
       "std        0.611463      0.469664  9.214488e+05   3867.971948   \n",
       "min        0.000000   2023.000000  1.000000e+04     66.230000   \n",
       "25%        1.000000   2023.000000  3.750000e+05   5460.325000   \n",
       "50%        1.000000   2023.000000  5.300000e+05   6854.840000   \n",
       "75%        1.000000   2024.000000  9.050000e+05   8750.000000   \n",
       "max        7.000000   2024.000000  2.250000e+07  68613.330000   \n",
       "\n",
       "       in_conservation_area    sqm_approx  \n",
       "count          37583.000000  37583.000000  \n",
       "mean               0.289972    100.511668  \n",
       "std                0.453755     60.871258  \n",
       "min                0.000000     10.000000  \n",
       "25%                0.000000     60.000000  \n",
       "50%                0.000000     80.000000  \n",
       "75%                1.000000    130.000000  \n",
       "max                1.000000    500.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ML.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c3ab768-2b8b-41db-b5f5-30350b4dc576",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['soldT'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m df_ML[\u001b[33m'\u001b[39m\u001b[33menergy_encoded\u001b[39m\u001b[33m'\u001b[39m] = df_ML[\u001b[33m'\u001b[39m\u001b[33mcurrentEnergyRating\u001b[39m\u001b[33m'\u001b[39m].map(energy_map)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# C. One-Hot Encoding for categorical columns\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Drop the columns not needed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df_ML = \u001b[43mdf_ML\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msoldT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m df_ML = pd.get_dummies(df_ML, columns=[\u001b[33m'\u001b[39m\u001b[33mpropertyType\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtenure\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconstruction_age_band\u001b[39m\u001b[33m'\u001b[39m], drop_first=\u001b[38;5;28;01mTrue\u001b[39;00m, prefix=[\u001b[33m'\u001b[39m\u001b[33mprop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtenure\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# D. Define features (X) and targets (y)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['soldT'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# A. Convert Rooms to Integers\n",
    "room_cols = ['bathrooms', 'bedrooms', 'livingRooms']\n",
    "df_ML[room_cols] = df_analysis[room_cols].astype(int)\n",
    "\n",
    "# B. Label Encode Energy Rating (Ordinal: A=7, G=1, NotRated=0)\n",
    "energy_map = {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1, 'NotRated': np.nan}\n",
    "df_ML['energy_encoded'] = df_ML['currentEnergyRating'].map(energy_map)\n",
    "\n",
    "# C. One-Hot Encoding for categorical columns\n",
    "# Drop the columns not needed\n",
    "df_ML = df_ML.drop(columns=['soldT'])\n",
    "df_ML = pd.get_dummies(df_ML, columns=['propertyType', 'tenure', 'construction_age_band'], drop_first=True, prefix=['prop', 'tenure', 'age'])\n",
    "\n",
    "# D. Define features (X) and targets (y)\n",
    "X = df_ML.drop(columns=['soldPrice']) \n",
    "y = np.log1p(df_ML['soldPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32347721-f600-4a1b-89d0-a680f9b736d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Target Encode Outcode (using median sqmPrice)\n",
    "outcode_medians = X_train.groupby('outcode')['sqmPrice'].median()\n",
    "global_median = X_train['sqmPrice'].median()\n",
    "X_train['neighborhood_value'] = X_train['outcode'].map(outcode_medians)\n",
    "\n",
    "X_test['neighborhood_value'] = X_test['outcode'].map(outcode_medians)\n",
    "X_test['neighborhood_value'] = X_test['neighborhood_value'].fillna(global_median)\n",
    "\n",
    "# E. Select final features (excluding the original strings and size_bucket)\n",
    "final_features = [\n",
    "    'neighborhood_value', 'bathrooms', 'bedrooms', 'floorAreaSqM', \n",
    "    'livingRooms', 'energy_encoded', 'tenure_Freehold', 'in_conservation_area', 'latitude', 'longitude'\n",
    "] + [col for col in df_ML.columns if 'propertyType_' in col or 'age' in col.lower()]\n",
    "\n",
    "X_train = X_train[final_features].astype(float)\n",
    "X_test = X_test[final_features].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "290dec27-a67f-4f7d-b739-cdb0d72d083e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a_gal\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in expm1\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m y_pred = np.expm1(y_pred_log)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 4. Calculate Metrics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m mse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m rmse = np.sqrt(mse)\n\u001b[32m     25\u001b[39m mae = mean_absolute_error(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:579\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[32m    530\u001b[39m \n\u001b[32m    531\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    575\u001b[39m \u001b[33;03m0.825...\u001b[39;00m\n\u001b[32m    576\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    577\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    578\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    582\u001b[39m )\n\u001b[32m    583\u001b[39m output_errors = _average(\n\u001b[32m    584\u001b[39m     (y_true - y_pred) ** \u001b[32m2\u001b[39m, axis=\u001b[32m0\u001b[39m, weights=sample_weight, xp=xp\n\u001b[32m    585\u001b[39m )\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:208\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001b[39;00m\n\u001b[32m    160\u001b[39m \n\u001b[32m    161\u001b[39m \u001b[33;03mExtends `_check_reg_targets` by automatically selecting a suitable floating-point\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    204\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    206\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m y_type, y_true, y_pred, sample_weight, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:114\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001b[39m\n\u001b[32m    111\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m    113\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m y_true = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m     )\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1083\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:133\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\DataAnalytics\\w8_9\\FP\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:182\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    168\u001b[39m     msg_err += (\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# 1. Initialize XGBoost Regressor\n",
    "# These parameters are \"safe defaults\" for regression\n",
    "xg_reg = xgb.XGBRegressor(\n",
    "    objective ='reg:squarederror', \n",
    "    n_estimators=500,        # More trees than Random Forest\n",
    "    learning_rate=0.05,      # Learn slower but better\n",
    "    max_depth=6,             # Tree depth\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train\n",
    "print(\"Training XGBoost\")\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict\n",
    "y_pred_log = xg_reg.predict(X_test)\n",
    "# Inverse log transform\n",
    "y_test = np.expm1(y_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# 4. Calculate Metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"XGBoost Results (Cleaned Data):\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"RMSE:     £{rmse:,.0f}\")\n",
    "print(f\"MAE:      £{mae:,.0f}\")\n",
    "print(f\"MAPE:     {mape:.2%}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b309cc-3baf-4826-baef-362b7279a943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
